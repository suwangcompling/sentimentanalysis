{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENSIM WORD2VEC EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING DATA: BROWN CORPUS\n",
    "**NB: FOR PREPARATION, DO NOT RUN THIS SECTION FIRST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 187 ms, total: 12.1 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words, sents = list(brown.words()), list(brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def brown_clean(sents):\n",
    "    sents = [[str(word.lower()) for word in sent] for sent in sents] # unicode->string, lowercasing.\n",
    "    sents = [[word for word in sent if word not in stop] for sent in sents] # removing stopwords.\n",
    "    sents = [[PorterStemmer().stem(word) for word in sent] for sent in sents] # lemmatizing.\n",
    "    return sents\n",
    "def brown_vocab_build(words):\n",
    "    return list(set([PorterStemmer().stem(str(word.lower())) for word in words if str(word.lower()) not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 s, sys: 204 ms, total: 23.2 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = brown_vocab_build(words)\n",
    "words = [str(word) for word in words] # somehow unicode->string needs to be performed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 197 ms, total: 22.5 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sents = brown_clean(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'fulton', u'counti', u'grand', u'juri', u'said', u'friday', u'investig', u\"atlanta'\", u'recent', u'primari', u'elect', u'produc', u'``', u'evid', u\"''\", u'irregular', u'took', u'place', u'.']\n",
      "fawn\n"
     ]
    }
   ],
   "source": [
    "print sents[0]\n",
    "print words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENSIM WORD2VEC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "    # Word2Vec params:\n",
    "    #  - size: dimensionality of feature vectors.\n",
    "    #  - window: the maximum distance between the current and predicted word within a sentence.\n",
    "    #  - alpha: initial learning rate.\n",
    "    #  - seed: seed for random number generator.\n",
    "    #  - min_count: ignore all words with total frequency lower than this.\n",
    "    #  - max_vocab_size: limit RAM during vocab building.\n",
    "    #  - sample: threshold for configuring which higher-frequency words are randomly downsampled\n",
    "    #      default=1e-3, useful range is (0, 1e-5).\n",
    "    #  - workers: use this many worker threads to train the model (i.e. faster with multicore machines)\n",
    "    #  - iter: number of iterations over corpus.\n",
    "    #  ... for the rest see https://radimrehurek.com/gensim/models/word2vec.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from keras.utils.np_utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/OJO/SPAM_INTEREST_TASKS/DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She has indeed contacted me I have n't contact...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The round of interviews went very well . Still...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It looks like my first reply might not have go...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We will be in Austin May NUMBER for the next r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- MLS # NUMBER is by far my top choice because...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  She has indeed contacted me I have n't contact...  1\n",
       "1  The round of interviews went very well . Still...  2\n",
       "2  It looks like my first reply might not have go...  2\n",
       "3  We will be in Austin May NUMBER for the next r...  2\n",
       "4  - MLS # NUMBER is by far my top choice because...  2"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joshdata = pd.read_excel('sentiment_josh.xlsx')\n",
    "joshdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cristinadata = pd.read_excel('sentiment_cristina.xlsx')\n",
    "jacobdata = pd.read_excel('sentiment_jacob.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She has indeed contacted me I have n't contacted her back because I 'm waiting to hear more about my husband 's job opportunity . He will be flying to Austin the day after Easter to continue the interviews and after that we should know more . If you could tell her that I will gladly contact her after that set of interviews that would be great\n",
      "[ 0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((joshdata[0].values, cristinadata[0].values, jacobdata[0].values))\n",
    "y = np.concatenate((joshdata[1].values, cristinadata[1].values, jacobdata[1].values))\n",
    "y[618] = 1.\n",
    "y[706] = 1.\n",
    "y[1472] = 1.\n",
    "y = to_categorical(y)\n",
    "print X[0]\n",
    "print y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_clean(sent):\n",
    "    sent = nltk.word_tokenize(sent) # still unicode.\n",
    "#     sent = [word for word in sent if word not in stop] # removing stopwords.\n",
    "    sent = [PorterStemmer().stem(word.lower()) for word in sent]\n",
    "    return sent\n",
    "def build_vocab(sents): # used after sent_clean operation.\n",
    "    vocab = []\n",
    "    for sent in sents:\n",
    "        vocab.extend(sent)\n",
    "    return list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = map(sent_clean, X)\n",
    "vocab = build_vocab(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'she', u'ha', u'inde', u'contact', u'me', u'i', u'have', u\"n't\", u'contact', u'her', u'back', u'becaus', u'i', u\"'m\", u'wait', u'to', u'hear', u'more', u'about', u'my', u'husband', u\"'s\", u'job', u'opportun', u'.', u'he', u'will', u'be', u'fli', u'to', u'austin', u'the', u'day', u'after', u'easter', u'to', u'continu', u'the', u'interview', u'and', u'after', u'that', u'we', u'should', u'know', u'more', u'.', u'if', u'you', u'could', u'tell', u'her', u'that', u'i', u'will', u'gladli', u'contact', u'her', u'after', u'that', u'set', u'of', u'interview', u'that', u'would', u'be', u'great']\n",
      "[u'smtp.homecity.com', u'lolthank', u'number-a', u'6pm', u'oldest', u'hate', u'whose', u'aug', u'sorri', u'deviat']\n"
     ]
    }
   ],
   "source": [
    "print X[0]\n",
    "print vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 543 ms, sys: 20.4 ms, total: 563 ms\n",
      "Wall time: 236 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(X, size=5, window=4) # words -> 10D vecs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WORD -> VECTOR\n",
    "def vectorize(model, sent): # sent -> list word vector in model.\n",
    "    return [model[word] for word in sent if word in model.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_vec = [vectorize(model,sent) for sent in X] # X_vec is now a list of lists of 10D vectors\n",
    "                                              #                 ^        ^            ^\n",
    "                                              #                 |        |            |\n",
    "                                              #               corpus   sentence     word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 1: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentence Length: 64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEZCAYAAAC0HgObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npfr/qPms4A2j910AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fdbaed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentLens = [len(sent) for sent in X_vec]\n",
    "meanLens = int(np.mean(sentLens))\n",
    "print 'Average Sentence Length: %d' % meanLens\n",
    "plt.hist(sentLens)\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('Length Frequency')\n",
    "plt.show()\n",
    "# NB: BUT WE'LL TAKE 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INPUT SIZE UNIFORMIZATION\n",
    "# FLATTENING\n",
    "def flatten(sents):\n",
    "    return [word for sent in sents for word in sent]\n",
    "padding = np.array([0.,0.,0.,0.,0.], dtype='float32')\n",
    "for i in range(len(X_vec)):\n",
    "    if len(X_vec[i]) > 60:\n",
    "        X_vec[i] = X_vec[i][:60]\n",
    "    else: \n",
    "        X_vec[i] += [padding for _ in range(60-len(X_vec[i]))]\n",
    "X_vec = map(np.array, X_vec) # to np.array, so that .shape attribute is available.\n",
    "X_vec = map(flatten, X_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_25 (Dense)                   (None, 100)         30100       dense_input_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                   (None, 50)          5050        dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                   (None, 3)           153         dense_26[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 35303\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# MLP BUILDING\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=300, init='normal', activation='relu'))\n",
    "model.add(Dense(50, init='normal', activation='relu'))\n",
    "model.add(Dense(3, init='normal', activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 8.11 µs\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 0s - loss: 1.0032 - acc: 0.4983 - val_loss: 0.9919 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.8997 - acc: 0.6100 - val_loss: 0.9454 - val_acc: 0.5567\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.8362 - acc: 0.6417 - val_loss: 0.9236 - val_acc: 0.5600\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.7658 - acc: 0.6617 - val_loss: 0.9161 - val_acc: 0.5900\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.6986 - acc: 0.6850 - val_loss: 0.8844 - val_acc: 0.5533\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.6506 - acc: 0.7117 - val_loss: 0.8613 - val_acc: 0.5767\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.6137 - acc: 0.7300 - val_loss: 0.8667 - val_acc: 0.5967\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.5507 - acc: 0.7608 - val_loss: 0.8487 - val_acc: 0.6300\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.4933 - acc: 0.7850 - val_loss: 0.8348 - val_acc: 0.6933\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.4784 - acc: 0.7825 - val_loss: 0.8124 - val_acc: 0.6667\n",
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=50, verbose=1)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print 'Accuracy: %.2f%%' % (scores[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 2: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 548 ms, sys: 60.1 ms, total: 608 ms\n",
      "Wall time: 320 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(X, size=5, window=4) # words -> 10D vecs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of EACH Sentence-Matrix: (1, 60, 5)\n",
      "Dimensions of ENTIRE Dataset: (1500, 1, 60, 5)\n"
     ]
    }
   ],
   "source": [
    "# SENTENCES -> MATRICES \n",
    "#  - each word is a row of 5D vector.\n",
    "#  - normalization size: 60.\n",
    "X_mat = [[model[word] for word in sent if word in model.vocab] for sent in X]\n",
    "padding = np.array([0.,0.,0.,0.,0.], dtype='float32')\n",
    "for i in range(len(X_mat)):\n",
    "    if len(X_mat[i]) > 60:\n",
    "        X_mat[i] = X_mat[i][:60]\n",
    "    else: \n",
    "        X_mat[i] += [padding for _ in range(60-len(X_mat[i]))]\n",
    "X_mat = map(np.array, X_mat) # to np.array, integrate individual flaot32 objs into 1 matrix.\n",
    "X_mat = np.array(X_mat)\n",
    "X_mat = X_mat.reshape(X_mat.shape[0], 1, 60, 5)\n",
    "print 'Dimensions of EACH Sentence-Matrix: (%d, %d, %d)' % X_mat[0].shape\n",
    "print 'Dimensions of ENTIRE Dataset: (%d, %d, %d, %d)' % X_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIMIZATION 1: ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_25 (Convolution2D)   (None, 30, 60, 5)   300         convolution2d_input_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)               (None, 30, 60, 5)   0           convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D)   (None, 15, 60, 5)   4065        dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_19 (MaxPooling2D)     (None, 15, 30, 2)   0           convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)               (None, 900)         0           maxpooling2d_19[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_49 (Dense)                   (None, 512)         461312      flatten_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)               (None, 512)         0           dense_49[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_50 (Dense)                   (None, 3)           1539        dropout_16[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 467216\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# MODEL BUILDING\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(30, 3, 3, input_shape=(1,60,5), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Convolution2D(15, 3, 3, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/25\n",
      "1200/1200 [==============================] - 1s - loss: 1.2828 - acc: 0.4908 - val_loss: 0.9881 - val_acc: 0.6033\n",
      "Epoch 2/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.9094 - acc: 0.5783 - val_loss: 0.9009 - val_acc: 0.5867\n",
      "Epoch 3/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.8693 - acc: 0.5933 - val_loss: 0.9105 - val_acc: 0.5967\n",
      "Epoch 4/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.8353 - acc: 0.6033 - val_loss: 0.9051 - val_acc: 0.6067\n",
      "Epoch 5/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.7768 - acc: 0.6408 - val_loss: 0.8126 - val_acc: 0.6567\n",
      "Epoch 6/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.7402 - acc: 0.6467 - val_loss: 0.8106 - val_acc: 0.6700\n",
      "Epoch 7/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.6939 - acc: 0.6883 - val_loss: 0.8017 - val_acc: 0.6467\n",
      "Epoch 8/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.6687 - acc: 0.6975 - val_loss: 0.7514 - val_acc: 0.7300\n",
      "Epoch 9/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.6177 - acc: 0.7333 - val_loss: 0.7830 - val_acc: 0.6700\n",
      "Epoch 10/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.5633 - acc: 0.7608 - val_loss: 0.7730 - val_acc: 0.6767\n",
      "Epoch 11/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.5363 - acc: 0.7600 - val_loss: 0.7504 - val_acc: 0.7033\n",
      "Epoch 12/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4974 - acc: 0.7900 - val_loss: 0.7318 - val_acc: 0.6900\n",
      "Epoch 13/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4876 - acc: 0.7942 - val_loss: 0.7656 - val_acc: 0.7400\n",
      "Epoch 14/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4421 - acc: 0.8133 - val_loss: 0.8037 - val_acc: 0.7100\n",
      "Epoch 15/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4385 - acc: 0.8025 - val_loss: 0.7848 - val_acc: 0.7233\n",
      "Epoch 16/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4179 - acc: 0.7983 - val_loss: 0.8003 - val_acc: 0.7167\n",
      "Epoch 17/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.3940 - acc: 0.8233 - val_loss: 0.8071 - val_acc: 0.7567\n",
      "Epoch 18/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.3935 - acc: 0.8200 - val_loss: 0.8258 - val_acc: 0.7333\n",
      "Epoch 19/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.3860 - acc: 0.8233 - val_loss: 0.7981 - val_acc: 0.7400\n",
      "Epoch 20/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.3930 - acc: 0.8133 - val_loss: 0.8505 - val_acc: 0.7167\n",
      "Epoch 21/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.3774 - acc: 0.8242 - val_loss: 0.8388 - val_acc: 0.7267\n",
      "Epoch 22/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.3661 - acc: 0.8350 - val_loss: 0.8499 - val_acc: 0.7400\n",
      "Epoch 23/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.3662 - acc: 0.8150 - val_loss: 0.8324 - val_acc: 0.7367\n",
      "Epoch 24/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.3579 - acc: 0.8275 - val_loss: 0.8279 - val_acc: 0.7500\n",
      "Epoch 25/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.3597 - acc: 0.8200 - val_loss: 0.8258 - val_acc: 0.7267\n",
      "Accuracy: 72.67%\n"
     ]
    }
   ],
   "source": [
    "# MODEL FITTING & EVALUATION\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=25, batch_size=50, verbose=1)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print 'Accuracy: %.2f%%' % (scores[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIMIZATION 2: SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_23 (Convolution2D)   (None, 30, 60, 5)   300         convolution2d_input_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)               (None, 30, 60, 5)   0           convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D)   (None, 15, 60, 5)   4065        dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_18 (MaxPooling2D)     (None, 15, 30, 2)   0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)               (None, 900)         0           maxpooling2d_18[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_47 (Dense)                   (None, 512)         461312      flatten_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)               (None, 512)         0           dense_47[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_48 (Dense)                   (None, 3)           1539        dropout_14[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 467216\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# MODEL BUILDING\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(30, 3, 3, input_shape=(1,60,5), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Convolution2D(15, 3, 3, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "epochs = 25\n",
    "lrate = .01\n",
    "decay = lrate / epochs\n",
    "sgd = SGD(lr=lrate, momentum=.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/25\n",
      "1200/1200 [==============================] - 1s - loss: 1.2144 - acc: 0.4817 - val_loss: 0.9562 - val_acc: 0.5733\n",
      "Epoch 2/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.9364 - acc: 0.5742 - val_loss: 0.9117 - val_acc: 0.6033\n",
      "Epoch 3/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.9162 - acc: 0.5675 - val_loss: 0.8962 - val_acc: 0.6200\n",
      "Epoch 4/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.8613 - acc: 0.6025 - val_loss: 0.8552 - val_acc: 0.6200\n",
      "Epoch 5/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.8419 - acc: 0.6083 - val_loss: 0.8855 - val_acc: 0.6000\n",
      "Epoch 6/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.8087 - acc: 0.6183 - val_loss: 0.8358 - val_acc: 0.6233\n",
      "Epoch 7/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.7817 - acc: 0.6250 - val_loss: 0.8298 - val_acc: 0.6333\n",
      "Epoch 8/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.7292 - acc: 0.6617 - val_loss: 0.8646 - val_acc: 0.5933\n",
      "Epoch 9/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.7149 - acc: 0.6625 - val_loss: 0.8282 - val_acc: 0.6667\n",
      "Epoch 10/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.6874 - acc: 0.6833 - val_loss: 0.7935 - val_acc: 0.6700\n",
      "Epoch 11/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.6612 - acc: 0.6992 - val_loss: 0.7768 - val_acc: 0.6700\n",
      "Epoch 12/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.6264 - acc: 0.7275 - val_loss: 0.7482 - val_acc: 0.7133\n",
      "Epoch 13/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.5824 - acc: 0.7417 - val_loss: 0.7548 - val_acc: 0.7067\n",
      "Epoch 14/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.5559 - acc: 0.7633 - val_loss: 0.7583 - val_acc: 0.7167\n",
      "Epoch 15/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.5416 - acc: 0.7592 - val_loss: 0.7752 - val_acc: 0.7267\n",
      "Epoch 16/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.5273 - acc: 0.7683 - val_loss: 0.7548 - val_acc: 0.7267\n",
      "Epoch 17/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.5080 - acc: 0.7800 - val_loss: 0.7620 - val_acc: 0.7333\n",
      "Epoch 18/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4749 - acc: 0.8000 - val_loss: 0.7543 - val_acc: 0.7367\n",
      "Epoch 19/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4649 - acc: 0.7950 - val_loss: 0.7731 - val_acc: 0.7500\n",
      "Epoch 20/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4567 - acc: 0.7975 - val_loss: 0.7758 - val_acc: 0.7267\n",
      "Epoch 21/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4372 - acc: 0.8050 - val_loss: 0.8010 - val_acc: 0.7333\n",
      "Epoch 22/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4462 - acc: 0.8025 - val_loss: 0.8513 - val_acc: 0.7200\n",
      "Epoch 23/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4034 - acc: 0.8192 - val_loss: 0.8216 - val_acc: 0.7133\n",
      "Epoch 24/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.3963 - acc: 0.8258 - val_loss: 0.8384 - val_acc: 0.7100\n",
      "Epoch 25/25\n",
      "1200/1200 [==============================] - 1s - loss: 0.4055 - acc: 0.8167 - val_loss: 0.8219 - val_acc: 0.7433\n",
      "Accuracy: 74.33%\n"
     ]
    }
   ],
   "source": [
    "# MODEL FITTING & EVALUATION\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=epochs, batch_size=50, verbose=1)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print 'Accuracy: %.2f%%' % (scores[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERGENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118f3cf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ADAM OPTIMIZATION\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(30, 3, 3, input_shape=(1,60,5), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Convolution2D(15, 3, 3, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=25, batch_size=50, verbose=0)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print 'Accuracy: %.2f%%' % (scores[1]*100)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuray')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SGD OPTIMIZATION\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(30, 3, 3, input_shape=(1,60,5), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Convolution2D(15, 3, 3, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "epochs = 25\n",
    "lrate = .01\n",
    "decay = lrate / epochs\n",
    "sgd = SGD(lr=lrate, momentum=.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=epochs, batch_size=50, verbose=0)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print 'Accuracy: %.2f%%' % (scores[1]*100)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuray')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
