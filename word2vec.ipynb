{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENSIM WORD2VEC EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING DATA: BROWN CORPUS\n",
    "**NB: FOR PREPARATION, DO NOT RUN THIS SECTION FIRST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 187 ms, total: 12.1 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words, sents = list(brown.words()), list(brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def brown_clean(sents):\n",
    "    sents = [[str(word.lower()) for word in sent] for sent in sents] # unicode->string, lowercasing.\n",
    "    sents = [[word for word in sent if word not in stop] for sent in sents] # removing stopwords.\n",
    "    sents = [[PorterStemmer().stem(word) for word in sent] for sent in sents] # lemmatizing.\n",
    "    return sents\n",
    "def brown_vocab_build(words):\n",
    "    return list(set([PorterStemmer().stem(str(word.lower())) for word in words if str(word.lower()) not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 s, sys: 204 ms, total: 23.2 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = brown_vocab_build(words)\n",
    "words = [str(word) for word in words] # somehow unicode->string needs to be performed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 197 ms, total: 22.5 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sents = brown_clean(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'fulton', u'counti', u'grand', u'juri', u'said', u'friday', u'investig', u\"atlanta'\", u'recent', u'primari', u'elect', u'produc', u'``', u'evid', u\"''\", u'irregular', u'took', u'place', u'.']\n",
      "fawn\n"
     ]
    }
   ],
   "source": [
    "print sents[0]\n",
    "print words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENSIM WORD2VEC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "    # Word2Vec params:\n",
    "    #  - size: dimensionality of feature vectors.\n",
    "    #  - window: the maximum distance between the current and predicted word within a sentence.\n",
    "    #  - alpha: initial learning rate.\n",
    "    #  - seed: seed for random number generator.\n",
    "    #  - min_count: ignore all words with total frequency lower than this.\n",
    "    #  - max_vocab_size: limit RAM during vocab building.\n",
    "    #  - sample: threshold for configuring which higher-frequency words are randomly downsampled\n",
    "    #      default=1e-3, useful range is (0, 1e-5).\n",
    "    #  - workers: use this many worker threads to train the model (i.e. faster with multicore machines)\n",
    "    #  - iter: number of iterations over corpus.\n",
    "    #  ... for the rest see https://radimrehurek.com/gensim/models/word2vec.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from keras.utils.np_utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/OJO/SPAM_INTEREST_TASKS/DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She has indeed contacted me I have n't contact...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The round of interviews went very well . Still...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It looks like my first reply might not have go...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We will be in Austin May NUMBER for the next r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- MLS # NUMBER is by far my top choice because...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  She has indeed contacted me I have n't contact...  1\n",
       "1  The round of interviews went very well . Still...  2\n",
       "2  It looks like my first reply might not have go...  2\n",
       "3  We will be in Austin May NUMBER for the next r...  2\n",
       "4  - MLS # NUMBER is by far my top choice because...  2"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joshdata = pd.read_excel('sentiment_josh.xlsx')\n",
    "joshdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cristinadata = pd.read_excel('sentiment_cristina.xlsx')\n",
    "jacobdata = pd.read_excel('sentiment_jacob.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She has indeed contacted me I have n't contacted her back because I 'm waiting to hear more about my husband 's job opportunity . He will be flying to Austin the day after Easter to continue the interviews and after that we should know more . If you could tell her that I will gladly contact her after that set of interviews that would be great\n",
      "[ 0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((joshdata[0].values, cristinadata[0].values, jacobdata[0].values))\n",
    "y = np.concatenate((joshdata[1].values, cristinadata[1].values, jacobdata[1].values))\n",
    "y[618] = 1.\n",
    "y[706] = 1.\n",
    "y[1472] = 1.\n",
    "y = to_categorical(y)\n",
    "print X[0]\n",
    "print y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_clean(sent):\n",
    "    sent = nltk.word_tokenize(sent) # still unicode.\n",
    "#     sent = [word for word in sent if word not in stop] # removing stopwords.\n",
    "    sent = [PorterStemmer().stem(word.lower()) for word in sent]\n",
    "    return sent\n",
    "def build_vocab(sents): # used after sent_clean operation.\n",
    "    vocab = []\n",
    "    for sent in sents:\n",
    "        vocab.extend(sent)\n",
    "    return list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = map(sent_clean, X)\n",
    "vocab = build_vocab(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'she', u'ha', u'inde', u'contact', u'me', u'i', u'have', u\"n't\", u'contact', u'her', u'back', u'becaus', u'i', u\"'m\", u'wait', u'to', u'hear', u'more', u'about', u'my', u'husband', u\"'s\", u'job', u'opportun', u'.', u'he', u'will', u'be', u'fli', u'to', u'austin', u'the', u'day', u'after', u'easter', u'to', u'continu', u'the', u'interview', u'and', u'after', u'that', u'we', u'should', u'know', u'more', u'.', u'if', u'you', u'could', u'tell', u'her', u'that', u'i', u'will', u'gladli', u'contact', u'her', u'after', u'that', u'set', u'of', u'interview', u'that', u'would', u'be', u'great']\n",
      "[u'smtp.homecity.com', u'lolthank', u'number-a', u'6pm', u'oldest', u'hate', u'whose', u'aug', u'sorri', u'deviat']\n"
     ]
    }
   ],
   "source": [
    "print X[0]\n",
    "print vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 543 ms, sys: 20.4 ms, total: 563 ms\n",
      "Wall time: 236 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(X, size=5, window=4) # words -> 10D vecs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WORD -> VECTOR\n",
    "def vectorize(model, sent): # sent -> list word vector in model.\n",
    "    return [model[word] for word in sent if word in model.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_vec = [vectorize(model,sent) for sent in X] # X_vec is now a list of lists of 10D vectors\n",
    "                                              #                 ^        ^            ^\n",
    "                                              #                 |        |            |\n",
    "                                              #               corpus   sentence     word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentence Length: 64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEZCAYAAAC0HgObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X28VVW97/HPF5FQE8QKKFDECMVK0YosK1flxYeO6O1B\nTSuVXj3pTXs4lti9L9l1eqF1Sj23rFdlhJWRZgalKZFuO2b4gBoqJHR9YIuyPSoRZnoAf/ePMRZO\nlvthsZlrr7223/frNV/MOeacY/7m3uz1W3OMMedURGBmZlaWIc0OwMzMBhcnFjMzK5UTi5mZlcqJ\nxczMSuXEYmZmpXJiMTOzUjmxmA0Akh6Q9K4S69tD0t8lqaT6viPpS3n+UEkdZdSb63ubpBVl1WfN\n58RiW8l/5H+U9DdJj0v6T0lvKKHekyX9ZxkxlqnsD/Q6jzlX0pe3Y/+TJW3KiePvkv6fpB9Kek11\nm4joiIgR0cuNavX+XiLiUxHx1WLRdsT/nKS9C3XfFBFT+lqfDTxOLLaFpF2BXwMXAaOAcUAb8GwZ\n1bMdH0b2AjdHxAhgJHAY8E9gqaT9trGeXn8vksr+nPD/g0HOicWKJgMREZdH8mxELI6Ie6obSJop\nabmkJyT9VtKehXXPSfqEpJWSnpT0rVy+L/Ad4C2SNkh6MpcPk/Tvkh6S9KikiyW9JK87VFKHpM9J\n6pS0RtIphWMNl/QNSQ9KWifpD4V9D85XXesk3Snp0L78MCT9S95/naSbJL2+sO4BSZ+X9Oe8/meS\nhhXWf0HSI5IelvTR6rd0SR8DTgK+kK82FhQOeWB39XUn/54eiIjTgRuB2fn4E/Ixh+TlU/KVTfUK\n54M9/F7m5t/F1ZI2AJUurrIkaZak/5J0v6QTCytukDSzsLzlqkjSjaRktizH8oHapjVJ++Y61km6\nW9LRhXVzJX1L0m/y/n+SNLG3n5P1s4jw5ImIANgV+C/gR8ARwG41648BVpIS0BDgHOCPhfXPAQtz\nPXsAjwHT87qTgT/U1HcB8CvSt+5dgAXAV/O6Q4GNwLnADsCRwD+AkXn9t4HrgbGkD6qDgR2BVwGP\nA4fn7d6dl1/WzTk/ALyri/IDgU7gjbn+D+dtdyzstwQYA+wGLAc+ntcdATwC7AsMB34MbAb2zuvn\nAl/uIo4u6+sithf8LHP5qcCjeX5CPuYQYGdgPTAprxsDTOnh9zIXWAccnJdfUoy58Lv5ev6ZvwN4\nCnhNXn8DMLO7ePP/k4mF5UOB1Xl+KLAK+GKefyfw90Ldc0n/R9+Qz+0nwGXN/tvxtPXkKxbbIiI2\nAG8j/eF/D3hM0gJJr8ibfAKYExErI+I54DxgqqQ9CtXMiYgNEdFB+oCZ2sMhPwZ8NiLWR8Q/cn0f\nLKz/b+ArEbE5In5L+vDaR5JIH6JnRMTaSJZExEbgQ8DVEXFdPqffA7cDR23jj+NjwHcj4vZc/49J\nTYIHF7a5KCI6I+JvpCbE6rl+AJgbEX+JiGfIVxF16K6+ej0C7N7Nus3A6yUNz8forbN8QUQsAYiI\nrppCA/g/EbExIv4AXA0ctw2xdjeo4C3ALhFxfkRsiogbgN+w9f+LqyJiaf4/+FO2/edkDebEYluJ\niPsiYmZE7Am8jnQFcGFePQG4KDdzPQk8QfqAGVeoorMw/zTw0q6Ok5PVzqR+gWp9vwVeVtjsifzh\nUVvfy0nfou/vouoJwHHVOiWtAw4BXlnH6dfW8/maesaTfh5V3Z3rq4DiqKkOuv8gLarrZ9eDccCT\ntYUR8TRwPPAp4FFJv5a0Ty919Tbqa11OmlUPsfXPpq9e2cWxH2Lr/2NrC/N9+TlZgzmxWLciYiWp\nWex1uagD+ERE7J6nURHx0uo3296qq1l+nPSh8NpCfbtFxMg66noceAZ4dRfrOoBLa2LcNSK+Vke9\ntfV8tYtz/Xkd+z5KSkJVe7L1+Teq8/p/Al2O8IqI30XEdFLT4X2kK9KeYuktxlGSdios70m6YoLU\nZLlzYd3YXuoqeoTUjFq0J7BmG+qwJnNisS0k7ZM7y8fl5T1ITRB/ypt8FzhHeeSRpJGS3l9n9Z3A\neEk7Qup0Br4PXFhtapM0TtL03irK+84FvinplZKG5A77HUlt7kdLmp7Lh+fO4Z6+TQ+T9JLCtEOO\n7ZOSpuXYdpF0lKRd6jjXy4FTcyf0zsD/7uJnsfcLd9smynENkbSXpP9L6quY3cU2oyXNyLFsJDUp\nVq8Et/q9bOPx2yTtKOntwHtI5w1wF/BeSTtJmgR8tGbftXR//rcAT+fBD0MlVYB/AX62jfFZEzmx\nWNEG4M3ALXk00M3AMuBfASLiV6R+kPmS/pbXHVHYv/ZbbnH5euBeYK2kx3LZ2cBfgSW5vkWkgQHd\nKdb3r8DdwG2kJrnzgCER8TBpkME5pE7eh/K2Pf1fv5p09fTP/O+5EbGU1M/yrdxMt5LUCd3duT6/\nIuJa4D9IfUwreT4xV/sqLgFem5vYftlbfd04WNLfSZ3yN5Cag94UEcu7iHEI8DnSt/7HSZ3tn8rr\nuvq91ONRUgf/I6TBCZ+IiFV53QWkBLaW9AXgJzX7zgYuzee/1ReT3E92NKlP7HHgW8CHC3V7qHIL\nUPry16DKpUtI3zY6I2L/mnWfJ40qeXlEVIc5zgJmApuAMyNiUS4/iNQkMxy4JiI+07CgzUqWh/Xe\nDbykps/IbFBq9BXLXODw2kJJ44H/Qfo2WS2bQhpVMoU0tPTiPPoH0lj7j0bEZGCypBfUaTaQSDpW\n6T6dUcD5wEInFXuxaGhiiYibSJfLtS4AzqopOwaYn4cYPkgayz5N0lhg14i4LW93KXBsg0I2K8sn\nSPfxrCI1C53W3HDM+s/Q/j6gpBlAR0Tcra2fjzeO59uiIbUHjyM1iz1cKH+YrYcemg04EXFks2Mw\na5Z+TSx5eOI5pGYwMzMbhPr7iuXVwF7An3P/yXjgjjykcw1pvHrV+Fy2hq3HtVfLuyTJo0bMzPog\nIkp5zUJ/DDdWnoiIeyJibETsHRETSc1aB0bEY6RnTB2fOzwnApOAWyNiLbBe0rScjD5CeqZUtxr9\nHJxGTueee27TY3gxxu74mz85/uZOZWpoYpF0GeleiMmSVks6tWaT4Pmks5x0g9Vy4BrgtHj+bE8n\njf1fCayKdJ+AmZkNQA1tCouIE3tZv3fN8hxgThfbLQVeX1tuZmYDj++8H2AqlUqzQ+izVo4dHH+z\nOf7Bo6F33jeDpBhs52Rm1miSiBbqvDczsxcRJxYzMyuVE4uZmZXKicXMzErlxGJmZqVyYjEzs1I5\nsZiZWamcWMzMrFT9/j6W/nDAAYf26/HOOus0PvSh4/v1mGZmA9WgvPMe2vvxiFdz/PFPMH/+Jf14\nTDOzcpV55/2gvGKB/rxi+SvpAc5mZgbuYzEzs5I5sZiZWamcWMzMrFROLGZmVionFjMzK5UTi5mZ\nlcqJxczMSuXEYmZmpXJiMTOzUjmxmJlZqRqaWCRdIqlT0rJC2dckrZB0l6QrJY0orJslaVVeP71Q\nfpCkZZJWSrqwkTGbmdn2afQVy1zg8JqyRcBrI2IqsAqYBSBpP+A4YApwJHCxpOoD0b4DfDQiJgOT\nJdXWaWZmA0RDE0tE3ASsqylbHBHP5cUlwPg8PwOYHxGbIuJBUtKZJmkssGtE3Ja3uxQ4tpFxm5lZ\n3zW7j2UmcE2eHwd0FNatyWXjgIcL5Q/nMjMzG4Ca9th8SV8CNkbEz8qvfXZhvpInMzOram9vp729\nvSF1NyWxSDoFOAp4V6F4DbBHYXl8LuuuvAeztz9IM7NBrFKpUKlUtiy3tbWVVnd/NIUpT2lBOgI4\nC5gREc8WtlsInCBpmKSJwCTg1ohYC6yXNC135n8EWNAPcZuZWR809IpF0mWkdqiXSVoNnAucAwwD\nfpcHfS2JiNMiYrmky4HlwEbgtHj+vcmnAz8ChgPXRMS1jYzbzMz6rqGJJSJO7KJ4bg/bzwHmdFG+\nFHh9iaGZmVmDNHtUmJmZDTJOLGZmVionFjMzK5UTi5mZlcqJxczMSuXEYmZmpXJiMTOzUjmxmJlZ\nqZxYzMysVE4sZmZWKicWMzMrlROLmZmVyonFzMxK5cRiZmalcmIxM7NSObGYmVmpnFjMzKxUTixm\nZlYqJxYzMyuVE4uZmZXKicXMzErlxGJmZqVyYjEzs1I1NLFIukRSp6RlhbJRkhZJuk/SdZJGFtbN\nkrRK0gpJ0wvlB0laJmmlpAsbGbOZmW2fRl+xzAUOryk7G1gcEfsA1wOzACTtBxwHTAGOBC6WpLzP\nd4CPRsRkYLKk2jrNzGyAaGhiiYibgHU1xccA8/L8PODYPD8DmB8RmyLiQWAVME3SWGDXiLgtb3dp\nYR8zMxtgmtHHMjoiOgEiYi0wOpePAzoK263JZeOAhwvlD+cyMzMbgIY2OwAgyq9ydmG+kiczM6tq\nb2+nvb29IXU3I7F0ShoTEZ25meuxXL4G2KOw3fhc1l15D2aXFauZ2aBUqVSoVCpbltva2kqruz+a\nwpSnqoXAKXn+ZGBBofwEScMkTQQmAbfm5rL1kqblzvyPFPYxM7MBpqFXLJIuI7VDvUzSauBc4Dzg\nCkkzgYdII8GIiOWSLgeWAxuB0yKi2kx2OvAjYDhwTURc28i4zcys73pNLJJ2iIjNfak8Ik7sZtVh\n3Ww/B5jTRflS4PV9icHMzPpXPU1hqyR9Pd9nYmZm1qN6EssBwErgB5KWSPq4pBENjsvMzFpUr4kl\nIjZExPcj4q3AF0n9JI9KmidpUsMjNDOzltJrYpG0g6QZkq4CLgS+AewN/Bq4psHxmZlZi6lnVNgq\n4Abg6xFxc6H8F5Le0ZiwzMysVdWTWPaPiKe6WhERZ5Qcj5mZtbh6Ou+/LWm36kJ+7P0PGxiTmZm1\nsHoSy/4R8bfqQkSsAw5sXEhmZtbK6kksQySNqi5I2p2B8fBKMzMbgOpJEN8A/iTpCtIzv94PfLWh\nUZmZWcvqNbFExKWSlgLvzEXvjYjljQ3LzMxaVb1NWn8hvQlyKICkPSNidcOiMjOzllXPQyg/Tbrb\nvhPYTGoOC2D/xoZmZmatqJ4rljOBfSLiiUYHY2Zmra+eUWEdwPpGB2JmZoNDPVcs9wPtkq4Gnq0W\nRsQ3GxaVmZm1rHoSy+o8DcuTmZlZt+oZbtwGIGnniHi68SGZmVkrq+ex+W+RtJw05BhJB0i6uOGR\nmZlZS6qn8/5C4HDgCYCI+DPgx+WbmVmX6kksRERHTdHmBsRiZmaDQD2d9x2S3gqEpB1J97WsaGxY\nZmbWquq5YvkkcDowDlgDTM3LZmZmL9BrYomIxyPipIgYExGjI+JDZdyFL+mzku6RtEzSTyUNyy8R\nWyTpPknXSRpZ2H6WpFWSVkiavr3HNzOzxqjnWWFzSc8G20pEzOzrQSW9Cvg0sG9E/LeknwMfBPYD\nFkfE1yR9EZgFnC1pP+A4YAowHlgs6TUR8YK4zMysueppCvsNcHWefg+MAJ4q4dg7ALtIGgrsRGpm\nOwaYl9fPA47N8zOA+RGxKSIeBFYB00qIwczMSlbPDZJXFpcl/Qy4aXsOGhGPSPoG6Y7+p4FFEbFY\n0piI6MzbrJU0Ou8yDvhToYo1uczMzAaYvrxi+DXA6F636oGk3UhXJxNID7i8QtJJvLDJrY9NXbML\n85U8mZlZVXt7O+3t7Q2pu54+lg2kD/jqe1jWAl/czuMeBtwfEU/mY1wFvBXorF61SBoLPJa3XwPs\nUdh/fC7rxuztDM/MbHCrVCpUKpUty21tbaXVXU9T2K6lHe15q4GDJQ0nPTH53cBtpL6bU4DzgZOB\nBXn7hcBPJV1AagKbBNzagLjMzGw71XPFclBP6yPijm09aETcKukXwJ3Axvzv94BdgcslzQQeIo0E\nIyKWS7ocWJ63P80jwszMBib19vksaQlwELCM1By2P3A78AwQEfGuRge5LSRFn7tm+uQSjj/+ZubP\nv6Qfj2lmVi5JRITKqKue4caPAG+IiDdGxBuAA4E1EfHOgZZUzMys+epJLPtExN3VhYi4h3SjopmZ\n2QvUM9x4maQfAD/JyyeRmsXMzMxeoJ7EcirwKdJTjQH+AHynYRGZmVlLq2e48TOSvgtcExH39UNM\nZmbWwup5NfEM4C7g2rw8VdLCRgdmZmatqZ7O+3NJD3z8G0BE3AVMbGRQZmbWuupJLBsjYn1NmW9O\nNDOzLtXTeX+vpBOBHSS9BjgDuLmxYZmZWauq54rl08BrSc/0uoz0NOLPNDIoMzNrXT1esUjaAfhy\nRPwr8KX+CcnMzFpZj1csEbEZeFs/xWJmZoNAPX0sd+bhxVcA/6gWRsQvGxaVmZm1rHoSy3DgCaD4\nwMkAnFjMzOwF6rnz/tT+CMTMzAaHbvtYJC0qzM/qn3DMzKzV9dR5/4rC/AcaHYiZmQ0OPSUW311v\nZmbbrKc+lr3zaDAV5reIiBkNjczMzFpST4nlmML8vzc6EDMzGxy6TSwRcWN/BmJmZoNDPc8KMzMz\nq5sTi5mZlappiUXSSElXSFoh6V5Jb5Y0StIiSfdJuk7SyML2syStyttPb1bcZmbWs3peTTxZ0vfz\nB/711amEY18EXBMRU4ADgL8AZwOLI2If4HpgVo5hP+A4YApwJHCxJJUQg5mZlayeZ4VdAXwX+D6w\nuYyDShoBvD0iTgGIiE3AeknHAIfmzeYB7aRkMwOYn7d7UNIq0uuSbykjHjMzK089iWVTRHyn5ONO\nBB6XNJd0tXI76eVhYyKiEyAi1koanbcfB/ypsP+aXGZmZgNMt4lF0u559teSTgOuIr1FEoCIeHI7\nj3sQcHpE3C7pAtKVSe3d/n28+392Yb6SJzMzq2pvb6e9vb0hdfd0xbKU9MFe7cs4q7AugL2347gP\nAx0RcXtevpKUWDoljYmITkljgcfy+jXAHoX9x+eybszejtDMzAa/SqVCpVLZstzW1lZa3T3dIDkR\nQNLwiHimuE7S8O05aE4cHZImR8RK4N3AvXk6BTgfOBlYkHdZCPw0X9mMAyYBt25PDGZm1hj19LHc\nTGq26q1sW51BShY7AvcDpwI7AJdLmgk8RBoJRkQsl3Q5sBzYCJwWEX5IppnZANRTH8tY0tXBTpIO\n5PkmsRHAztt74Ij4M/CmLlYd1s32c4A523tcMzNrrJ6uWA4nNUuNB75ZKN8AnNPAmMzMrIX11Mcy\nD5gn6X0RcWU/xmRmZi2snj6WCZI+V1O2HlgaEXc1ICYzM2th9Twr7I3AJ0n9LeOATwBHAN+X9IUG\nxmZmZi2oniuW8cBBEfEUgKRzgauBd5Dudfla48IzM7NWU88Vy2gKd9yThvuOiYh/1pSbmZnVdcXy\nU+AWSdWbFY8GLpO0C+m+EjMzsy16TSwR8RVJ1wJvzUWfLDyK5aSGRWZmZi2pnisWgDtIz+YaCiBp\nz4hY3bCozMysZfWaWCR9GjgX6CS9j0Wkh1Du39jQzMysFdVzxXImsE9EPNHoYMzMrPXVMyqsg3RD\npJmZWa/quWK5H2iXdDVbv+jrm93vYmZmL1b1JJbVeRqWJzMzs27VM9y4DUDSzhHxdONDMjOzVtZr\nH4ukt0haDvwlLx8g6eKGR2ZmZi2pns77C0nvZnkCtryg6x2NDMrMzFpXPYmFiOioKdrcgFjMzGwQ\nqKfzvkPSW4HI76c/E1jR2LDMzKxV1XPF8kngdNK7WNYAU4HTGhmUmZm1rnpGhT1OzcMmJX2G1Pdi\nZma2lbr6WLpQ+6piMzMzoO+JRaVGYWZmg0ZfE0uUcXBJQyTdIWlhXh4laZGk+yRdJ2lkYdtZklZJ\nWiFpehnHNzOz8nWbWCRtkPT3LqYNwKtKOv6ZbP0WyrOBxRGxD3A9MCvHsh9wHDAFOBK4WJKvmszM\nBqBuE0tE7BoRI7qYdo2Iel8Q1i1J44GjgB8Uio8B5uX5ecCxeX4GMD8iNkXEg8AqYNr2xmBmZuXr\na1NYGS4AzmLrZrUxEdEJEBFrgdG5fBzp8f1Va3KZmZkNMNt95dEXkt4DdEbEXZIqPWzax76c2YX5\nSp7MzKyqvb2d9vb2htTdlMQCHALMkHQUsBOwq6QfA2sljYmITkljgcfy9muAPQr7j89l3ZjdiJjN\nzAaNSqVCpVLZstzW1lZa3U1pCouIcyJiz4jYGzgBuD4iPgz8Gjglb3YysCDPLwROkDRM0kRgEnBr\nP4dtZmZ1aNYVS3fOAy6XNBN4iDQSjIhYLuly0giyjcBpEVHKkGczMytX0xNLRNwI3JjnnwQO62a7\nOcCcfgzNzMz6oJmjwszMbBByYjEzs1I5sZiZWamcWMzMrFROLGZmVionFjMzK5UTi5mZlcqJxczM\nSuXEYmZmpXJiMTOzUjmxmJlZqZxYzMysVE4sZmZWKicWMzMrlROLmZmVyonFzMxK5cRiZmalcmIx\nM7NSObGYmVmpnFjMzKxUTixmZlYqJxYzMyuVE4uZmZWqKYlF0nhJ10u6V9Ldks7I5aMkLZJ0n6Tr\nJI0s7DNL0ipJKyRNb0bcZmbWu2ZdsWwCPhcRrwXeApwuaV/gbGBxROwDXA/MApC0H3AcMAU4ErhY\nkpoSuZmZ9agpiSUi1kbEXXn+KWAFMB44BpiXN5sHHJvnZwDzI2JTRDwIrAKm9WvQZmZWl6b3sUja\nC5gKLAHGREQnpOQDjM6bjQM6CrutyWVmZjbADG3mwSW9FPgFcGZEPCUpajapXa7T7MJ8JU9mZlbV\n3t5Oe3t7Q+puWmKRNJSUVH4cEQtycaekMRHRKWks8FguXwPsUdh9fC7rxuzS4zUzG0wqlQqVSmXL\ncltbW2l1N7Mp7IfA8oi4qFC2EDglz58MLCiUnyBpmKSJwCTg1v4K1MzM6teUKxZJhwAnAXdLupPU\n5HUOcD5wuaSZwEOkkWBExHJJlwPLgY3AaRHRx2YyMzNrpKYkloj4I7BDN6sP62afOcCchgVlZmal\naPqoMDMzG1ycWMzMrFROLGZmVionFjMzK5UTi5mZlcqJxczMSuXEUoIFC65CUr9OY8fu1ezTNjPr\nUlOfFTZYPPPMOvr8WLM+6uz0WwPMbGDyFYuZmZXKicXMzErlxGJmZqVyYjEzs1I5sZiZWamcWMzM\nrFROLGZmVionFjMzK5UTi5mZlcqJxczMSuXEYmZmpfKzwlrWS5D693lhY8ZMYO3aB/v1mGbWepxY\nWtaz+MGXZjYQuSnMzMxK1VKJRdIRkv4iaaWkLzY7HjMze6GWSSyShgDfAg4HXgt8UNK+zY2qEdqb\nHUCftbe3NzuE7eL4m8vxDx4tk1iAacCqiHgoIjYC84FjmhxTA7Q3O4A+a/U/LMffXI5/8GilxDIO\n6CgsP5zLzMxsABmUo8JGjDi63461ceNq/vnPfjtck/U+xLmtra30ow4ZsjPPPfd06fV2pRp/fx6z\nysO5G2vs2L3o7Hyooceo/f//Yv2dKqJ/h6z2laSDgdkRcURePhuIiDi/ZrvWOCEzswEmIkq5p6CV\nEssOwH3Au4FHgVuBD0bEiqYGZmZmW2mZprCI2CzpfwGLSH1DlzipmJkNPC1zxWJmZq2hlUaF9agV\nbp6UNF7S9ZLulXS3pDNy+ShJiyTdJ+k6SSML+8yStErSCknTmxf9lniGSLpD0sK83Eqxj5R0RY7n\nXklvbrH4PyvpHknLJP1U0rCBHL+kSyR1SlpWKNvmeCUdlM95paQLmxz/13J8d0m6UtKIVoq/sO7z\nkp6TtHtD4o+Ilp9ICfKvwARgR+AuYN9mx9VFnGOBqXn+paQ+o32B84Ev5PIvAufl+f2AO0lNlnvl\nc1STz+GzwE+AhXm5lWL/EXBqnh8KjGyV+IFXAfcDw/Lyz4GTB3L8wNuAqcCyQtk2xwvcArwpz18D\nHN7E+A8DhuT584A5rRR/Lh8PXAs8AOyey6aUGf9guWJpiZsnI2JtRNyV558CVpB+yccA8/Jm84Bj\n8/wMYH5EbIqIB4FVpHNtCknjgaOAHxSKWyX2EcDbI2IuQI5rPS0Sf7YDsIukocBOwBoGcPwRcROw\nrqZ4m+KVNBbYNSJuy9tdWtinobqKPyIWR8RzeXEJ6e8XWiT+7ALgrJqyYygx/sGSWFru5klJe5G+\nTSwBxkREJ6TkA4zOm9We1xqae17V/5DFjrlWiX0i8Likubkp73uSdqZF4o+IR4BvAKtzLOsjYjEt\nEn/B6G2Mdxzp77lqIP1tzyR9g4cWiV/SDKAjIu6uWVVq/IMlsbQUSS8FfgGcma9cakdQDLgRFZLe\nA3TmK66exroPuNizocBBwLcj4iDgH8DZtMDPHkDSbqRvlRNIzWK7SDqJFom/B60WLwCSvgRsjIif\nNTuWeknaCTgHOLfRxxosiWUNsGdheXwuG3ByM8YvgB9HxIJc3ClpTF4/Fngsl68B9ijs3szzOgSY\nIel+4GfAuyT9GFjbArFD+qbVERG35+UrSYmmFX72kNr274+IJyNiM3AV8FZaJ/6qbY13wJ2HpFNI\nTcInFopbIf5Xk/pP/izpgRzLHZJG0/1naJ/iHyyJ5TZgkqQJkoYBJwALmxxTd34ILI+IiwplC4FT\n8vzJwIJC+Ql59M9EYBLpxtB+FxHnRMSeEbE36ed7fUR8GPg1Azx2gNz80iFpci56N3AvLfCzz1YD\nB0saLkmk+Jcz8OMXW1/hblO8ublsvaRp+bw/UtinP2wVv6QjSM3BMyLi2cJ2Az7+iLgnIsZGxN4R\nMZH0ZevAiHgsx398afH3x+iE/piAI0ijrFYBZzc7nm5iPATYTBq1didwR457d2Bxjn8RsFthn1mk\nERorgOnNPocc06E8PyqsZWIHDiB9CbkL+CVpVFgrxX9ujmUZqeN7x4EcP3AZ8AjpdaergVOBUdsa\nL/AG4O78t31Rk+NfBTyU/3bvAC5upfhr1t9PHhVWdvy+QdLMzEo1WJrCzMxsgHBiMTOzUjmxmJlZ\nqZxYzMysVE4sZmZWKicWMzMrlROLDQqSvpQfKf/n/CywN/WxngMkHVl2fHUee4Kk2mc4lX2MMyUN\nLyxvaOTx7MXJicVanqSDSY/YmBoRB5Aef9LR817dmprrapZG31j2GWCXfjyevQg5sdhg8Erg8YjY\nBBDpeVoVDTppAAADFElEQVRrYctLitol3Sbpt4XnVN0g6TxJtyi9IO4QSTsCXwaOy1c9H5C0c35h\n0hJJSyUdnfc/Ob/o6bdKL606vxqM0kvnlkq6U9LvclmX9dRD0t75OLdJurH6WJr8pOaLJP1R0l8l\nvTeXS9LFkpYrvVTraknvlfRp0gMsr5f0++er178pvbjqZkmv2L5fhRmD55Eunl68E+kb+J3AX4Bv\nA+/I5UOBPwIvy8vHAZfk+RuAr+f5I4Hf5fmTgf8o1P1V4MQ8P5L0KJKd8nZ/Jb2w7SXAg6THib+c\n9PiMPfM+u/VUT815TKDmpUy5fDHw6jw/Dfh9np8L/DzPTyG9kwjg/cBv8vwY4EngvXn5AWBUoe7n\ngKPy/PnAOc3+fXpq/WloH3KR2YASEf+QdBDwduBdwHxJZwNLgdcBv8sP0BtCenZS1S/zv0tJH+pd\nmQ4cLan6YqRhPP8U2N9Heu0Bku7NdewO3BgRq3Nsf+ulnvt6OjdJu5CeYnxFPgdIzwir+lU+zor8\nlFpIz6S7Ipd3SrqhttrC/LMRUX2nyFJSM6LZdnFisUEhIgL4A/CH3AH+EdJDAu+JiEO62a36dNrN\n9Py38L6IWFUsyP06xafbPleoo7v31bygnjoMAdZFeodMV4ox9PSenO5sLMz39nMwq4v7WKzlSZos\naVKhaCrpCbT3Aa/ISQBJQyXt1101+d8NwIhC+XXAGYVjTe0lnCXA2yVNyNuP2sZ6tkoOEbEBeEDS\n+wv77t/Lvn8E3pf7WsYAlcI2f2fr8+tLMjLrkROLDQYvBebl4cZ3kfobZkfERlJ/w/m5/E7gLXmf\n7t68eAOwX7XzHvgKsKOkZZLuIXXudyUAIuJx4OPAVZLuBObn9f9WqOfuHuqZLGm1pI787/uAk4CP\n5g72e0jvV+/pHK4kvWvjXtI7ypcC6/O67wPXFjrvPSrMSufH5psNQpJ2yX1PuwO3AIdEeqGTWcO5\nPdVscPqNpN1IHf1fdlKx/uQrFjMzK5X7WMzMrFROLGZmVionFjMzK5UTi5mZlcqJxczMSuXEYmZm\npfr/qPms4A2j910AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fdbaed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentLens = [len(sent) for sent in X_vec]\n",
    "meanLens = int(np.mean(sentLens))\n",
    "print 'Average Sentence Length: %d' % meanLens\n",
    "plt.hist(sentLens)\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('Length Frequency')\n",
    "plt.show()\n",
    "# NB: BUT WE'LL TAKE 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INPUT SIZE UNIFORMIZATION\n",
    "# FLATTENING\n",
    "def flatten(sents):\n",
    "    return [word for sent in sents for word in sent]\n",
    "padding = np.array([0.,0.,0.,0.,0.], dtype='float32')\n",
    "for i in range(len(X_vec)):\n",
    "    if len(X_vec[i]) > 60:\n",
    "        X_vec[i] = X_vec[i][:60]\n",
    "    else: \n",
    "        X_vec[i] += [padding for _ in range(60-len(X_vec[i]))]\n",
    "X_vec = map(np.array, X_vec) # to np.array, so that .shape attribute is available.\n",
    "X_vec = map(flatten, X_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_25 (Dense)                   (None, 100)         30100       dense_input_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                   (None, 50)          5050        dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                   (None, 3)           153         dense_26[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 35303\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# MLP BUILDING\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=300, init='normal', activation='relu'))\n",
    "model.add(Dense(50, init='normal', activation='relu'))\n",
    "model.add(Dense(3, init='normal', activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 8.11 µs\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 0s - loss: 1.0032 - acc: 0.4983 - val_loss: 0.9919 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.8997 - acc: 0.6100 - val_loss: 0.9454 - val_acc: 0.5567\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.8362 - acc: 0.6417 - val_loss: 0.9236 - val_acc: 0.5600\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.7658 - acc: 0.6617 - val_loss: 0.9161 - val_acc: 0.5900\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.6986 - acc: 0.6850 - val_loss: 0.8844 - val_acc: 0.5533\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.6506 - acc: 0.7117 - val_loss: 0.8613 - val_acc: 0.5767\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.6137 - acc: 0.7300 - val_loss: 0.8667 - val_acc: 0.5967\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.5507 - acc: 0.7608 - val_loss: 0.8487 - val_acc: 0.6300\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.4933 - acc: 0.7850 - val_loss: 0.8348 - val_acc: 0.6933\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 0s - loss: 0.4784 - acc: 0.7825 - val_loss: 0.8124 - val_acc: 0.6667\n",
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=50, verbose=1)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print 'Accuracy: %.2f%%' % (scores[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
